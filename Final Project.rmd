  
---
title: "MLR"
author: "Brian Dehlinger"
date: "December 1, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r cars, echo=FALSE}
set.seed(1223)
remove_singularities <- function(dataset, gene_name){
  dataset_copy <- dataset
  item <- paste(gene_name, "~.", sep="")
  full_formula <- as.formula(item)
  fit <- lm(full_formula, data=dataset)
  singularities <- attributes(alias(fit)$Complete)$dimnames[[1]]
  for (singularity in singularities){
    dataset_copy[singularity] <- NULL
  }
  return(dataset_copy)
}
read_in_pruned_datasets_for_gene_0.8 <- function(gene_name, path){
  full_path0.8 <- paste(path, gene_name, "_for_r_0.8.txt", sep="")
  Data0.8 <- read.table(full_path0.8, header=TRUE, sep=',')
  Data0.8 <- remove_singularities(Data0.8, gene_name)
  return(Data0.8)
}
#install.packages("DAAG")
#install.packages("caret")
#install.packages("lmtest")
#install.packages("MASS")
#install.packages("car")
#install.packages("reshape")
#install.packages("plotmo")
#install.packages("olsrr")
library(caret)
library(lmtest)
library(MASS)
library(car)
library(reshape)
library(plotmo)
library(olsrr)
library(DAAG)
# We notice that the Expression Data is skewed to the right. 
gene_data <- read_in_pruned_datasets_for_gene_0.8("ENSG00000142794", "F:\\")
gene_data <- as.data.frame(gene_data)
print(gene_data)
hist(gene_data[["ENSG00000142794"]], main="ENSG0000014279 Gene Expression Distribution", ylab="Frequency", xlab="Gene Expression Value")
boxplot(gene_data[["ENSG00000142794"]])
trainIndex <- createDataPartition(gene_data[["ENSG00000142794"]], p=.8, list = FALSE, times=1)
gene_data <- gene_data[trainIndex,]
gene_test <- gene_data[-trainIndex,]
```



```{r diagnostics}
model <- lm(ENSG00000142794~., data=gene_data)
summary(model)
plot(model, which=1)
plot(model, which=2)
plot(model, which=3)
plot(model, which=4)
plot(model, which=5)
# We note from the Residuals Vs Fitted Plot that there might be a slight concern with nonconstant variance but for the Breusch-Pagan test we fail to reject with an alpha of 0.05. However,
# we notice an issue with normality from a QQPlot that suggests the data is skewed and we reject the shapiro-wilks test with an alpha of 0.05 The Scale-Location plot has a slope most likely because there isn't enough data for the fitted values beyond the 2.
# We don't notice an issues with overly influential points in the residuals vs Leverage Plot.
shapiro.test(model$residuals)
bptest(model)
# We have an adjusted R-squared of 0.5114. However, we note that there is severe multicolinearity and many model terms are non significant. Thus, this model is overly complex and needs to be pruned.
# Ideally, we would like to have variable selection with a penalty term.
# But first we will correct this model using BoxCox and then evaluate it on the test dataset using RMSE as an evaluator of model accuracy. We note that although RMSE may be good we would like to 
# have a simpler model(with less predictors) and deal with multicolinearity that gives us about the same or less RMSE on the testing dataset. 
n <- nrow(gene_data)
p <- length(model$coefficients)
car::vif(model)
```

```{r pressure, echo=FALSE}
# The added variable plots suggest a lot of the predictors do not add new information when the other predictors are included in the model.
pdf("AddedVariablesBeforeSelection.pdf")
avPlots(model, ask=FALSE)
dev.off()
```


```{r transform_data}
transformed_gene_data <- gene_data
transformed_gene_test <- gene_test
transformed_gene_data[["ENSG00000142794"]] <- 1/(sqrt(transformed_gene_data[["ENSG00000142794"]]+2))
transformed_gene_test[["ENSG00000142794"]] <- 1/(sqrt(transformed_gene_test[["ENSG00000142794"]]+2))
n <- nrow(transformed_gene_data)
boxplot(transformed_gene_data["ENSG00000142794"])
```

```{r refit MLR}
model <- lm(ENSG00000142794~., data=transformed_gene_data)


selected_p <- ols_step_backward_p(model, prem=0.01)
selected_p_model <- selected_p$model
selected_p$adjr
selected_p$sbc

# We choose P-values to only get significant terms in our model. This will hopefully improve the Added Variable Plots and still give a reasonable model. 
selected<- stepAIC(model, k=log(n))
model <- selected
p <- length(selected$coefficients)
RSS_selected <- c(crossprod(selected$residuals))
MSE <- RSS_selected / length(selected$residuals)
sqrt(MSE)

model <- selected_p_model
```


```{r Diagnostics}
summary(model)
plot(model, which=1)
plot(model, which=2)
plot(model, which=3)
plot(model, which=4)
plot(model, which=5)
shapiro.test(model$residuals)
bptest(model)

pdf("AddedVariablesAfterSelection.pdf")
avPlots(model, ask=FALSE)
dev.off()
car::vif(model)
car::vif(selected)
```

```{r New Coefficients, Leverage, DFBetas(Sensitivity Analysis)}



cd <- cooks.distance(model)
which(cd > 4 / (n-p))
transformed_gene_dropped <- model$model[-c(which(cd > 4 / (n-p))),]
new_model <- lm(ENSG00000142794~., data=transformed_gene_dropped)
model$coefficients 
new_model$coefficients
summary(model)
summary(new_model)


# We note that we would like to retain these points regardless as they are interesting and represent variation in the population that can be informative in clinical situations. We opt to not use Robust Regression since the effect on the final model is not serious enough. We will separately analyze DFBetas to make sure this is the case. 


leverage_threshold <- (3*(p))/n
leverage_threshold
leverage_values <- hatvalues(model)
which(leverage_values > leverage_threshold)

# We choose a value of 0.11 as a threshold for outliers and print the maximum value below.


betas <- as.data.frame(dfbetas(model))

to_remove <- c()
for(column in betas){
  outliers <- which(abs(column) > 0.11)
  print(max(abs(column)))
  print(which(abs(column) == max(abs(column))))
  print(outliers)
  to_remove <- union(to_remove, outliers)
}

transformed_gene_dropped_betas <- model$model[-c(to_remove),]
new_model_betas <- lm(ENSG00000142794~., data=transformed_gene_dropped_betas)
model$coefficients 
new_model$coefficients
summary(model)
summary(new_model_betas)



predictions <- predict(model, transformed_gene_test)
# We want to know the RMSE of the test set to get an understanding of the predictive abilities of this model.
RMSE(predictions, transformed_gene_test[["ENSG00000142794"]])
validation_model_one <- lm(ENSG00000142794~rs12734589+rs1976403+rs10737458+rs113324018+rs972662+rs41290414, data=transformed_gene_test)
sigma(model)^2
sigma(validation_model_one)^2
summary(model)$adj.r.squared
summary(validation_model_one)$adj.r.squared
press(model)
press(validation_model_one)

#MSPR
mean((transformed_gene_test[["ENSG00000142794"]]-predictions)^2)

predictions_new_model <- predict(new_model, transformed_gene_test)
# We want to know the RMSE of the test set to get an understanding of the predictive abilities of this model.
RMSE(predictions_new_model, transformed_gene_test[["ENSG00000142794"]])
ols_plot_dfbetas(model)
validation_new_model <- lm(ENSG00000142794~rs12734589+rs1976403+rs10737458+rs113324018+rs972662+rs41290414, data=transformed_gene_test)
sigma(validation_new_model)^2
summary(validation_new_model)$adj.r.squared
press(validation_new_model)

#MSPR
mean((transformed_gene_test[["ENSG00000142794"]]-predictions_new_model)^2)


predictions_bic_selected_model <- predict(selected, transformed_gene_test)
RMSE(predictions_bic_selected_model, transformed_gene_test[["ENSG00000142794"]])


validation_model_two <- lm(ENSG00000142794 ~ rs12734589 + rs1976403 + rs1814737 + 
    rs17420195 + rs10737458 + rs904927 + rs113324018 + rs972662 + 
    rs41290414 + rs115933091, data=transformed_gene_test)

sigma(selected)^2
sigma(validation_model_two)^2
summary(selected)$adj.r.squared
summary(validation_model_two)$adj.r.squared
press(selected)
press(validation_model_two)
mean((transformed_gene_test[["ENSG00000142794"]]-predictions_bic_selected_model)^2)

vif(model)
```

```{r}
# We get a RMSE of 0.055 which is pretty good and suggests that this model has the potential to generalize well already. However, we are extremely concerned about multicolinearity. We might
# want to futher study specific SNPs for example.
# If we change the way the test/train split is done(different seed) we note that the model performs similary within the range of 0.04 to 0.05 for RMSE suggesting this is probably an accurate measure # of the accuracy resulting from this kind of workflow for this gene and the combined information we can extract from the predictors.

predictions_bic_selected_model <- predict(selected, transformed_gene_test)
RMSE(predictions_bic_selected_model, transformed_gene_test[["ENSG00000142794"]])


validation_model_two <- lm(ENSG00000142794 ~ rs12734589 + rs1976403 + rs1814737 + 
    rs17420195 + rs10737458 + rs904927 + rs113324018 + rs972662 + 
    rs41290414 + rs115933091, data=transformed_gene_test)

sigma(selected)^2
sigma(validation_model_two)^2
summary(selected)$adj.r.squared
summary(validation_model_two)$adj.r.squared
press(selected)
press(validation_model_two)
mean((transformed_gene_test[["ENSG00000142794"]]-predictions_bic_selected_model)^2)

# Even though this has a lower RMSE we choose the first model since it has less predictors and is more likely to generalize well to independent data and doesn't have colinearity. It can better explain what is going on in a downstream model that incoporates gene expression.
```










